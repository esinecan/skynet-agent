# === LLM Provider Configuration ===
# Configure one or more AI providers (Skynet Agent uses Vercel AI SDK for multi-provider support)

# Google Gemini (recommended for embeddings and general use)
GOOGLE_API_KEY=your_gemini_api_key_here

# OpenAI (for GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic (for Claude models)  
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# === Model Selection ===
# Choose your default LLM model (can be overridden per request)
# Format: provider:model-name

# Google Gemini models (recommended default - working model from config.json)
# AGENT_MODEL=google:gemini-2.5-flash-preview-05-20

# Other Gemini options:
# AGENT_MODEL=google:gemini-2.0-flash
# AGENT_MODEL=google:gemini-1.5-pro
# AGENT_MODEL=google:gemini-1.5-flash

# OpenAI models (requires OPENAI_API_KEY)
# AGENT_MODEL=openai:gpt-4o
# AGENT_MODEL=openai:gpt-4o-mini
# AGENT_MODEL=openai:gpt-3.5-turbo

# Anthropic models (requires ANTHROPIC_API_KEY)
# AGENT_MODEL=anthropic:claude-3-5-sonnet-20241022
# AGENT_MODEL=anthropic:claude-3-5-haiku-20241022

# Server Configuration
PORT=9000
MCP_SERVER_PORT=8081

# Sentry Configuration
SENTRY_DSN=your_backend_sentry_dsn_here
SENTRY_ENVIRONMENT=development
SENTRY_RELEASE=skynet-agent@0.1.0
SENTRY_TRACES_SAMPLE_RATE=1.0
SENTRY_PROFILES_SAMPLE_RATE=1.0

# MCP Server Configuration
# JSON string containing MCP server configurations (takes precedence over config.json)
# Example: {"playwright":{"transport":"stdio","command":"npx","args":["@playwright/mcp@latest"]}}
# SKYNET_MCP_SERVERS_JSON='{}'

# ChromaDB Configuration (Primary vector database)
CHROMA_PATH=./data/chroma
CHROMA_COLLECTION=skynet_memories

# Memory Configuration
# Memory consolidation schedule (cron format)
MEMORY_CONSOLIDATION_SCHEDULE="0 2 * * *"  # 2 AM daily
# Directory for memory data (fallback and legacy)
MEMORY_DIR=./data/memory

# Autonomous Behavior
# Minutes of inactivity before triggering autonomous actions
IDLE_THRESHOLD_MINUTES=10
